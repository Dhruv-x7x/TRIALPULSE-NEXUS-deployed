"""
TRIALPULSE NEXUS - Pattern Watcher v1.0
========================================
Monitor for emerging issues and patterns before they escalate.
"""

import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, field
from collections import defaultdict
import threading

logger = logging.getLogger(__name__)


@dataclass
class PatternAlert:
    """An alert generated by pattern detection."""
    alert_id: str
    pattern_type: str
    severity: str  # info, warning, critical
    title: str
    description: str
    affected_entities: List[str]
    metric_values: Dict[str, float]
    recommended_action: str
    detected_at: datetime = field(default_factory=datetime.now)
    acknowledged: bool = False
    
    def to_dict(self) -> Dict:
        return {
            "alert_id": self.alert_id,
            "pattern_type": self.pattern_type,
            "severity": self.severity,
            "title": self.title,
            "description": self.description,
            "affected_entities": self.affected_entities,
            "metric_values": self.metric_values,
            "recommended_action": self.recommended_action,
            "detected_at": self.detected_at.isoformat(),
            "acknowledged": self.acknowledged
        }


class PatternWatcher:
    """
    Monitor for emerging issues and patterns.
    
    Watches for:
    - DQI score degradation trends
    - Query volume spikes
    - Clean rate declining
    - Site underperformance
    - Resolution time increases
    """
    
    def __init__(self):
        self._patterns: Dict[str, Callable] = {}
        self._alerts: List[PatternAlert] = []
        self._metric_history: Dict[str, List[tuple]] = defaultdict(list)
        self._thresholds: Dict[str, float] = {
            "dqi_decline_rate": -2.0,  # Alert if DQI drops by >2 points
            "query_spike_factor": 1.5,  # Alert if queries increase by 50%
            "clean_rate_drop": -5.0,    # Alert if clean rate drops by 5%
            "resolution_time_increase": 1.3,  # Alert if resolution time increases 30%
        }
        self._running = False
        self._watch_thread: Optional[threading.Thread] = None
        
        # Register default pattern detectors
        self._register_default_patterns()
    
    def _register_default_patterns(self):
        """Register default pattern detection functions."""
        self.register_pattern("dqi_degradation", self._detect_dqi_degradation)
        self.register_pattern("query_spike", self._detect_query_spike)
        self.register_pattern("clean_rate_decline", self._detect_clean_rate_decline)
        self.register_pattern("site_underperformance", self._detect_site_underperformance)
        self.register_pattern("resolution_slowdown", self._detect_resolution_slowdown)
    
    def register_pattern(self, pattern_name: str, detector: Callable):
        """Register a pattern detection function."""
        self._patterns[pattern_name] = detector
        logger.debug(f"Registered pattern detector: {pattern_name}")
    
    def record_metric(self, metric_name: str, value: float, 
                     entity_id: Optional[str] = None):
        """Record a metric value for trend analysis."""
        key = f"{metric_name}:{entity_id}" if entity_id else metric_name
        self._metric_history[key].append((datetime.now(), value))
        
        # Keep only last 24 hours of data
        cutoff = datetime.now() - timedelta(hours=24)
        self._metric_history[key] = [
            (t, v) for t, v in self._metric_history[key] if t > cutoff
        ]
    
    def get_metric_trend(self, metric_name: str, 
                        entity_id: Optional[str] = None,
                        hours: int = 4) -> Optional[float]:
        """
        Calculate trend for a metric over specified hours.
        
        Returns:
            Change per hour, or None if not enough data
        """
        key = f"{metric_name}:{entity_id}" if entity_id else metric_name
        history = self._metric_history.get(key, [])
        
        if len(history) < 2:
            return None
        
        cutoff = datetime.now() - timedelta(hours=hours)
        recent = [(t, v) for t, v in history if t > cutoff]
        
        if len(recent) < 2:
            return None
        
        # Simple linear trend
        first_time, first_value = recent[0]
        last_time, last_value = recent[-1]
        
        hours_elapsed = (last_time - first_time).total_seconds() / 3600
        if hours_elapsed < 0.1:
            return None
        
        return (last_value - first_value) / hours_elapsed
    
    def check_patterns(self, data: Dict[str, Any]) -> List[PatternAlert]:
        """
        Run all pattern detectors on provided data.
        
        Args:
            data: Current state data to analyze
            
        Returns:
            List of generated alerts
        """
        alerts = []
        
        for pattern_name, detector in self._patterns.items():
            try:
                pattern_alerts = detector(data)
                if pattern_alerts:
                    alerts.extend(pattern_alerts)
            except Exception as e:
                logger.error(f"Pattern detector {pattern_name} failed: {e}")
        
        self._alerts.extend(alerts)
        return alerts
    
    # Default pattern detectors
    
    def _detect_dqi_degradation(self, data: Dict) -> List[PatternAlert]:
        """Detect declining DQI scores."""
        alerts = []
        patients = data.get("patients", [])
        
        # Group by site and check trends
        site_dqi = defaultdict(list)
        for p in patients:
            site_id = p.get("site_id")
            dqi = p.get("dqi_score")
            if site_id and dqi:
                site_dqi[site_id].append(dqi)
        
        threshold = self._thresholds["dqi_decline_rate"]
        
        for site_id, scores in site_dqi.items():
            trend = self.get_metric_trend("dqi", site_id)
            if trend and trend < threshold:
                import uuid
                alerts.append(PatternAlert(
                    alert_id=f"alrt_{uuid.uuid4().hex[:8]}",
                    pattern_type="dqi_degradation",
                    severity="warning",
                    title=f"DQI Degradation at {site_id}",
                    description=f"DQI scores declining at {abs(trend):.1f} points/hour",
                    affected_entities=[site_id],
                    metric_values={"trend": trend, "avg_dqi": sum(scores)/len(scores)},
                    recommended_action="Review site data quality processes"
                ))
        
        return alerts
    
    def _detect_query_spike(self, data: Dict) -> List[PatternAlert]:
        """Detect sudden increase in queries."""
        alerts = []
        
        current_queries = data.get("total_open_queries", 0)
        trend = self.get_metric_trend("open_queries")
        
        if trend and trend > self._thresholds["query_spike_factor"] * 10:
            import uuid
            alerts.append(PatternAlert(
                alert_id=f"alrt_{uuid.uuid4().hex[:8]}",
                pattern_type="query_spike",
                severity="warning",
                title="Query Volume Spike Detected",
                description=f"Query count increasing rapidly",
                affected_entities=[],
                metric_values={"current": current_queries, "trend": trend},
                recommended_action="Investigate data quality issues"
            ))
        
        return alerts
    
    def _detect_clean_rate_decline(self, data: Dict) -> List[PatternAlert]:
        """Detect declining clean patient rates."""
        alerts = []
        
        clean_rate = data.get("clean_rate", 0)
        trend = self.get_metric_trend("clean_rate")
        
        if trend and trend < self._thresholds["clean_rate_drop"]:
            import uuid
            alerts.append(PatternAlert(
                alert_id=f"alrt_{uuid.uuid4().hex[:8]}",
                pattern_type="clean_rate_decline",
                severity="critical",
                title="Clean Rate Declining",
                description=f"Clean patient rate dropping at {abs(trend):.1f}%/hour",
                affected_entities=[],
                metric_values={"current_rate": clean_rate, "trend": trend},
                recommended_action="Prioritize data cleaning efforts"
            ))
        
        return alerts
    
    def _detect_site_underperformance(self, data: Dict) -> List[PatternAlert]:
        """Detect underperforming sites."""
        alerts = []
        sites = data.get("sites", [])
        
        for site in sites:
            dqi_mean = site.get("dqi_mean", 100)
            if dqi_mean < 80:
                import uuid
                alerts.append(PatternAlert(
                    alert_id=f"alrt_{uuid.uuid4().hex[:8]}",
                    pattern_type="site_underperformance",
                    severity="warning",
                    title=f"Site Underperforming: {site.get('site_id')}",
                    description=f"Mean DQI of {dqi_mean:.1f} is below threshold",
                    affected_entities=[site.get('site_id')],
                    metric_values={"dqi_mean": dqi_mean},
                    recommended_action="Schedule site quality review"
                ))
        
        return alerts
    
    def _detect_resolution_slowdown(self, data: Dict) -> List[PatternAlert]:
        """Detect increasing resolution times."""
        alerts = []
        
        avg_resolution_time = data.get("avg_resolution_time_hours", 0)
        trend = self.get_metric_trend("resolution_time")
        
        if trend and trend > 0.5:  # Increasing by 0.5 hours per hour
            import uuid
            alerts.append(PatternAlert(
                alert_id=f"alrt_{uuid.uuid4().hex[:8]}",
                pattern_type="resolution_slowdown",
                severity="info",
                title="Resolution Time Increasing",
                description=f"Average resolution time trending up",
                affected_entities=[],
                metric_values={"current_avg": avg_resolution_time, "trend": trend},
                recommended_action="Review resolution workflow efficiency"
            ))
        
        return alerts
    
    def get_active_alerts(self, severity: Optional[str] = None) -> List[PatternAlert]:
        """Get unacknowledged alerts."""
        alerts = [a for a in self._alerts if not a.acknowledged]
        if severity:
            alerts = [a for a in alerts if a.severity == severity]
        return alerts
    
    def acknowledge_alert(self, alert_id: str) -> bool:
        """Acknowledge an alert."""
        for alert in self._alerts:
            if alert.alert_id == alert_id:
                alert.acknowledged = True
                return True
        return False
    
    def get_stats(self) -> Dict[str, Any]:
        """Get watcher statistics."""
        return {
            "patterns_registered": len(self._patterns),
            "total_alerts": len(self._alerts),
            "active_alerts": len([a for a in self._alerts if not a.acknowledged]),
            "critical_alerts": len([a for a in self._alerts if a.severity == "critical" and not a.acknowledged]),
            "metrics_tracked": len(self._metric_history)
        }


# Singleton
_watcher: Optional[PatternWatcher] = None


def get_pattern_watcher() -> PatternWatcher:
    """Get the global PatternWatcher instance."""
    global _watcher
    if _watcher is None:
        _watcher = PatternWatcher()
    return _watcher
